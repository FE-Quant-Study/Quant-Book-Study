{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 머신러닝 프로세스\n",
    "\n",
    "- 6장에서 다는 내용\n",
    "    - 데이터로부터의 지 및 비지도학습의 작동법\n",
    "    - 회귀와 분류 작업을 위한 지학습 모델의 훈련과 평가\n",
    "    - 편향 분산 트레이드오프가 예측 성과에 미치는 방법\n",
    "    - 과대적합에 기인한 예측 오차를 진단하고 다루는 방법\n",
    "    - 시계열 데이터에 초점을 맞추고 하이퍼파라미터를 최적화하고자 교차 검증을 사용하는 방법\n",
    "    - 표본 외 테스트를 수행할 때 금융 데이터가 추가적인 주의를 요하는 이유\n",
    "\n",
    "## 데이터로부터 머신러닝이 작동하는 방법\n",
    "### 도전 과제: 알고리즘을 작업에 매칭\n",
    "- 자동 학습의 가장 큰 도전 과제는 새로운 데이터에 대해서도 모델의 학습이 일반화될 수 있게 훈련 데이터에서 의미 있는 패턴을 인식하는 것임\n",
    "- 훈련 데이터는 알고리즘이 미래에 작업을 수행할 때 당면할 더 커다란 현상들의 일부 표본만으로 형성되는 반면 모델이 인식해야 하는 잠재적 패턴은 더 많이 존재함\n",
    "- 알고리즘이 학습할 수 있는 패턴의 형태는 알고리즘이 표현하는 함수들을 포함하는 가설 공간(hypothesis space)의 크기에 의해 제한됨\n",
    "\n",
    "### 지도학습: 예제에 의한 학습\n",
    "- 지도학습은 가장 흔히 사용되는 형태의 ML\n",
    "- 지도학습은 입력과 출력 데이터 간의 함수적 관계를 반영하는 데이터에서 이러한 관계를 포착하고, 이러한 학습을 적용해 새로운 데이터에 대해 유효함 명제를 도출하게 하는 것이 목적임\n",
    "\n",
    "- 데이터로부터의 입력-결과 관계를 학습해 새로운 입력의 결과에 대한 정확한 예측을 수행하는 작업은 중요한 트레이드오프에 직면함\n",
    "- 모델이 복잡할 수록 암시적인 관계를 표현할 수 있는 유연한 부분은 더욱 많이 갖게되지만 이 경우 일반적인 패턴을 나타내는 체계적 신호가 아니라 훈련 표본에 특별한 무작위 잡음을 학습할 가능성이 커짐 (과대적합)\n",
    "\n",
    "### 비지도학습: 유용한 패턴의 발견\n",
    "- 비지도학습 문제를 풀 때는 특성만을 관찰하며 결과에 대한 측정을 갖지 않음\n",
    "- 비지도학습은 미래 결과를 예측하거나 변수 간의 관계를 추론하는 대신 데이터에 포함된 정보의 새로운 표현을 허용하는 구조를 식별하는 것을 목적으로함\n",
    "- 관측간의 공통성이나 클러스터를 식별하는 것 또는 관련 정보를 포착하는 압축된 요약 표현을 얻고자 특성을 변환하는 것을 포함함\n",
    "\n",
    "\n",
    "#### 사용 사례: 리스크 관리에서 텍스트 처리까지\n",
    "- 유사한 리스크와 수익률 성격을 지닌 자산들을 그룹화하는 것 (13장의 계층적 리스크 패리티)\n",
    "- 주성분 분석(13장)과 오토인코더(19장)을 활용한 훨신 많은 수의 증권의 성과를 내는 작은 수의 리스크 팩터를 찾는 것\n",
    "- 일련의 문서(어닝콜 원고 같은)에서 가장 중요한 측면을 포함하는 잠재적인 주제를 식별하는 것(14장)\n",
    "\n",
    "#### 클러스터링 알고리즘: 유사한 관측을 찾는것\n",
    "- 클러스터링 알고리즘(Clustering Algorithm)은 유사도(Similarity)를 적용해 비교 가능한 정보를 지닌 관측치들이나 데이터 특성들을 식별함\n",
    "- 수많은 데이터 포인트 더 작은 수의 클러스터에 할당해 데이터 세트를 요약함\n",
    "\n",
    "- 많이 쓰이는 클러스터링 알고리즘\n",
    "    - K-평균 클러스터링(k-means clustering)  \n",
    "        : 데이터 포인트는 타원형을 취하는 동일 크기 k 클러스터의 하나에 속함\n",
    "    - 가우시안 혼합 모델(Gaussian mixture models)  \n",
    "        : 데이터 포인트는 여러 개의 다변량 정규 분포 중 하나에 의해 생성됨\n",
    "    - 밀도 기반 클러스터(Density-based cluster)  \n",
    "        : 클러스터는 임의의 모양을 가지며, 근접하는 데이터 포인트의 최소 개수의 존재에 의해서만 정의됨\n",
    "    - 계층적 클러스터(Hierarchical cluster)  \n",
    "        : 데이터 포인트는 순차적으로 더 작은 수의 클러스터에 결합되면서 형성되는 상위 그룹에 속함\n",
    "\n",
    "#### 차원 축소: 정보의 압축\n",
    "- 차원축소(Dimensionality Reduction)는 원천 데이터에 포함된 가장 중요한 정보를 포착하는 새로운 데이터를 산출함\n",
    "- 기존 데이터를 클러스터로 그룹화하는 것이 아니라 더 적은 특성을 이용해 원래의 정보를 표현하는 목적으로 데이터를 변환함\n",
    "- 데이터를 변환하는 방법 / 압축한 정보에 따른 종류\n",
    "    - 주성분 분석(PCA, Pricipal Component Analysis)  \n",
    "        : 기존 데이터 세트의 분산을 가장 많이 포착하는 선형 변환을 찾음\n",
    "    - 매니폴드 학습  \n",
    "        : 데이터의 저차원 표현을 산출하는 비선형 변환을 찾음\n",
    "    - 오토인코더(AutoEncoder)  \n",
    "        : 신경망을 이용해 정보의 손실을 최소화하면서 데이터를 비선형적으로 압축\n",
    "\n",
    "\n",
    "### 강화학습\n",
    "- 환경에 의해 주어진 정보를 기반으로 매 타임스텝에서 행동을 선택하는 에전트에 초점을 맞춘다\n",
    "- 에이전트는 환경의 현재 상태를 묘사하는 일련의 관측치를 기반으로 시간에 걸쳐 가장 큰 보상을 산출하는 행동을 선택하는 것을 목적으로 함 (동적인 동시에 상호작용적)\n",
    "- 양과 음의 보상 흐름은 알고리즘의 학습에 영향을 주며, 지금 취한 행동이 환경과 미래 보상 모두에 영향을 줄 수 있음\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## 머신러닝 워크플로\n",
    "- 알고리즘 트레이딩을 위한 ML 해법을 개발하려면 자원을 경제적으로 사용하면서 성공 확률을 극대화할 수 있는 체계적인 접근법이 필요함 (+ 투명성 + 재현 가능)\n",
    "\n",
    "> \"문제 정의와 성공척도\" -> \"데이터 수집, 정제 및 검증\" -> \"특성 탐색, 추출 및 공학\" -> \"머신러닝 알고리즘 선택\" -> \"모델 설계와 하이퍼파라미터 교차 검증\" -> \"모델 실행과 예측\"\n",
    "\n",
    "### 기본 설명: k-최근접 이웃\n",
    "- k-최근접 이웃(KNN, K-Nearest Neighbors) 알고리즘을 회구와 분류 문제 모두 수행 가능\n",
    "\n",
    "### 문제의 구성: 목적과 성과 측정\n",
    "- 목적은 변수 간의 연관관계 또는 인과관계를 식별하기 위한 통계적 추론이지만 더 많은 경우 목적은 트레이딩 손호를 산출하고자 결과를 예측하는 것\n",
    "- 연속 출력 변수 : 회귀 문제 / 범주형 변수 : 분류 / 순서가 있는 범주형 변수 : 순윔 문제를 의미\n",
    "- 여러 알파 팩터를 효율적으로 결합하는 방법을 찾는 것!\n",
    "\n",
    "#### 예측 대 추론\n",
    "- 지도학습 알고즘에 의해 산출된 함수 관계는 추론(inference)를 위해 사용될 수 있음 (결과가 생성되는 방법에 대한 통찰력을 얻고자 사용할 수 있음)\n",
    "- 알고리즘 트레이딩의 경우 추론을 사용해 수익률의 리스크 팩터에 대한 인과적 또는 통계적 의존성을 추정할 수 있음\n",
    "- 추론은 원래 데이터를 생성했던 프로세스에 대한 가정에 따라 달라짐\n",
    "\n",
    "#### 인과 추론: 상광관계는 인과를 의미하지 않는다\n",
    "- 인과 추론(Causal Inferecne)의 목적은 특정 입력값이 특정 출력값을 의미하는 관계를 식별하는 것\n",
    "    - 다른 모든 변수가 고정됐다고 가정했을 때 일련의 특정 매크로 변수들이 주어진 자산 가격을 특정 방향으로 움직이게 하는 관계를 식별하는 것\n",
    "\n",
    "#### 회귀: 인기 있는 손실 함수와 오차 척도\n",
    "- 회귀 문제는 연속 변수를 예측하는 것을 목표로함\n",
    "- 평균제곱근오차(RMSE, Root Mean Squared Error)는 가장 인기가 좋은 손실 함수이며 오차 척도인데, 적어도 미분 가능하기 떄문임\n",
    "    - 평균 제곱근 오차는 타깃이 지수적으로 증가할 때 적합\n",
    "- 평균 절대 오차(MAE, Mean Absolute Error)와 중앙값 절대 오차(MedAE, Mdeian Absolute Error)\n",
    "    - 대칭적이나 큰 오차에 더 큰 가중치를 주지않음 MedAE는 특이값에 민감하지 않음\n",
    "- 설명된 분산 점수(explained variance score)\n",
    "    - 모델이 설명하는 타깃 분산의 부분이며 0~1사이의 값을 갖음\n",
    "    - R2 점수 or 결정 계수는 잔차의 평균이 0이며 동일한 결과를 산출하지만 아닌 경우 다른 결과를 가질 수 있음 (표본 외 데이터에 대해 계산할 때 음이 될 수 있음)   \n",
    "\n",
    "<img src='./img/6-1.png'></img>\n",
    "\n",
    "#### 분류: 혼동 행렬의 이해\n",
    "- 분류 문(classification problem)는 범주형 결과 변수를 갖음\n",
    "- 대부분의 예측기는 어떤 관측이 특정 클래스에 속하는가를 나타내는 점수를 산출\n",
    "- 음성과 양성 클래스 레이블을 가진 이진 분류의 경우 점수는 전형적으로 0과 1로 변화하거나 이에 맞춰 정규화됨\n",
    "\n",
    "### ROC는 곡선 아래 면적을 특징짓는다.\n",
    "- ROC(Receiver Operationg Characteristics)곡선은 성과를 기반으로 분류기(classifier)를 시각화, 비교, 선택하게 함\n",
    "- 임계값을 사용해 모든 예측 점수에 대한 클래스를 예측하고 이로부터 나오는 모든 조합의 TPR과 FPR을 계산, 이들 쌍을 각 면의 길이가 1인 정사각형 안에 시각화함\n",
    "- AUC(Area Under the Curve)는 ROC 그래프 아래의 면적으로 정의 (0.5와 최대 1사이로 변함)\n",
    "- 분류기의 AUC는 분류기가 랜덤하게 선택된 양성의 경우를 랜덤하게 선택된 음성의 경우보다 더 높게 순위를 매길 확률을 나타내는 중요한 통계적 특성이 있음 (클래스 불균형에 덜 민감)\n",
    "\n",
    "\n",
    "### 정밀도-재현율 곡선\n",
    "- 한 클래스에 대한 관ㅅ미이 특별히 있는 경우 정밀도-재현율 곡선(PRC, Precision-Recall Curve)는 여러 임계값에 대한 오차 척도 간의 트레이드 오프를 시각화함\n",
    "    - 재현율(Recall)은 분류기가 주어진 임계값에 대해 양성으로 예측하는 클래스 멤버의 실제 양성 비중을 측정함. 이는 정보 검색에서 유래한 것으로 검색 알고리즘에 의해 성공적으로 식별된 관련 문서의 비중을 측정함\n",
    "    - 정밀도(Precision)은 양성 예측 중 참인 비중을 측정함   \n",
    "    - F1 Score는 주어진 임계값에 대해 정밀도와 재현율의 조화 평균 (2개의 척도가 취하는 상대적 비중을 고려하면서 임계값을 수치적으로 최적화하는 데 사용할 수 있음)\n",
    "\n",
    "### 데이터의 수집과 준비\n",
    "- 빠른 탐색과 반복 시행을 가능하게 하는 빠른 접근을 허용하는 폼새으로 저장할 필요 있음 (HDF와 parquet 포맷 권장)\n",
    "\n",
    "### 특서 탐험, 추출, 특성 공학\n",
    "- 개별 변수의 분포 및 결과와 특성 간의 관계를 이해하는 것이 적절한 알고리즘을 선택하는 기반이 됨\n",
    "- 상관계수와 같은 선형 척도에서 4장의 정보 계수를 소개할 때 나오는 스피어맨 순위 상관계수와 같은 비선형 통계량에 이르는 수치적 평가름 포함함\n",
    "- 체계적 탐험 분석(Exploratory analysis)은 성공적 예측 모델의 가장 중요한 단일 재료가됨\n",
    "    - 특성 공학(Feature Engineering)은 원시 데이터 형태로는 알고리즘이 접근 가능하지 못하는 데이터에 포함된 정보를 추출함\n",
    "    - 도메인에 대한 전문 지식, 통계학과 정보 이론의 적용 및 창의성 등으로부터 도움을 받음\n",
    "\n",
    "#### 정보 이론을 활용한 특성 평가\n",
    "- 특성과 결과 간의 상호 정보량(MI, Mutual Information)은 두 변수 간 상호 의존성의 척도\n",
    "\n",
    "### ML 알고리즘 선택\n",
    "\n",
    "### 모델 설계와 조정\n",
    "- ML 프로게스는 모델의 일반화 오차(Generalization Error)의 추정에 기반을 두고 모델의 복잡성을 진단하고 관리하는 스텝을 포함\n",
    "- ML 프로세스의 중요한 목적은 통계적으로 건전하고 효율적인 절차를 사용해 일반화 오차의 불편 추정치(Unbiased Estimate)를 얻는 것\n",
    "- 모델 설계와 조정 프로세스를 관리하는 핵심은 편향 분산 트레이드오프가 과소적합과 과대적합에 어떻게 연관되는가를 이해하는 것\n",
    "\n",
    "#### 편향과 분산의 트레이드오프\n",
    "- ML 모댈의 예측 오차는 축소 가능한 부분과 불가능한 부분으로 분리될 수 있음\n",
    "    - 축소 불가능한 부분은 관련 변수의 부재, 자연적 변이(natural variation)또는 측정 오차(measurement error)에 기인한 데이터의 랜덤 변이(random variation/잡음)에 기인함\n",
    "* 편향에서 기인한 에러  \n",
    "    : 가정이 너무 단순해서 참 함수 관계의 복잡도를 포착할 수 없음  \n",
    "    : 모델이 참 함수를 학습하고자 할 때는 언제나 체계적인 실수를 해서 예측은 평균적으로 유사한 정도로 편향 (과소적합)\n",
    "* 분산에서 기인한 에러  \n",
    "    : 알고리즘이 참 관계의 관점에 비해 너무 복잡한 경우\n",
    "    : 참 관계를 포착하지 않고 데이터를 과대적합화해 잡음으로부터 패턴을 추출\n",
    "    : 결과적으로 각 표본에서 상이한 함수 관계를 학습하고 표본외 예측의 변동이 매우 큼\n",
    "\n",
    "\n",
    "#### 학습곡선\n",
    "- 학습곡선(Learning Curve)은 함수 관계를 학습하고자 사용된 데이터 세트의 크기에 따라 훈련과 테스트 오차가 어떻게 되는가를 그래프로 그림\n",
    "- 주어진 모델의 편향 분산 트레이드오프를 진단하는 데 유용하며, 표본 크기가 증가하면 예측 성과가 개선되는지에 대한 의문의 해답을 제공함\n",
    "- 높은 편향을 가진 모델은 표본 내와 표본 외 모두에 대해 높은, 그러나 유사한 훈련 오차를 가진다.\n",
    "\n",
    "\n",
    "### 모델 선택을 위한 교차 검증의 활용\n",
    "- 모델 선택의 목적은 새로운 데이터가 주어졌을 때 가장 낮은 예측 오차를 산출하는 모델을 식별하는 것\n",
    "- 좋으 선택은 일반화 오차의 불편 추정치를 요구하며, 모델 훈련의 부분이 아니었던 데이터에 대한 테스트를 필요로 한다.\n",
    "- 교차 검증(CV / Cross-Validation)\n",
    "    - 각 분할이 검증 세트로 한번 사용되고 나머지는 훈련 세트로 사용되도록 수행함\n",
    "    - 데이터의 일부는 알고리즘을 훈련하는 데 사용되고 나머지 부분은 알고리즘의 예측 성능을 추정하는 데 사용된다.\n",
    "- 데이터를 분할할 때는 여러가지를 고려\n",
    "    - 데이터의 양, 오차 추정치의 분산, 계산적 강도, 클래스 레이블 간의 비율 유지와 같은 데이터의 구조적 측면을 데이터 분할 시 고려"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 파이썬으로 교차 검증을 구현하는 방법\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 2\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = list(range(1, 11))\n",
    "train_, test_ = train_test_split(data, test_size=0.2)\n",
    "print(len(train_), len(test_))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K폴드 반복기\n",
    "- K 폴드 반복기는 데이터 세트를 중복되지 않게 분할 (분리된 각 데이터 세트를 검증 세트에 1번찍 할당)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 2 3 4 5 6 7 9] [1 8]\n",
      "[1 2 3 4 6 7 8 9] [0 5]\n",
      "[0 1 3 4 5 6 8 9] [2 7]\n",
      "[0 1 2 3 5 6 7 8] [4 9]\n",
      "[0 1 2 4 5 7 8 9] [3 6]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=5, random_state=42, shuffle=True)\n",
    "\n",
    "for train, val in kf.split(data):\n",
    "    print(train, val)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 단일 잔류 교차 검증\n",
    "- 각각 하나의 관측을 검증 세트로 사용하는 단일 잔류법(Leave-one-out method)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4 5 6 7 8 9] [0]\n",
      "[0 2 3 4 5 6 7 8 9] [1]\n",
      "[0 1 3 4 5 6 7 8 9] [2]\n",
      "[0 1 2 4 5 6 7 8 9] [3]\n",
      "[0 1 2 3 5 6 7 8 9] [4]\n",
      "[0 1 2 3 4 6 7 8 9] [5]\n",
      "[0 1 2 3 4 5 7 8 9] [6]\n",
      "[0 1 2 3 4 5 6 8 9] [7]\n",
      "[0 1 2 3 4 5 6 7 9] [8]\n",
      "[0 1 2 3 4 5 6 7 8] [9]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import LeaveOneOut\n",
    "\n",
    "loo = LeaveOneOut()\n",
    "for train, val in loo.split(data):\n",
    "    print(train ,val)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### P개 잔류 교차 검증\n",
    "- 단일 잔류 교차 검증과 유사 (P개를 남겨 검증 데이터로 사용)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 3 4 5 6 7 8 9] [0 1]\n",
      "[1 3 4 5 6 7 8 9] [0 2]\n",
      "[1 2 4 5 6 7 8 9] [0 3]\n",
      "[1 2 3 5 6 7 8 9] [0 4]\n",
      "[1 2 3 4 6 7 8 9] [0 5]\n",
      "[1 2 3 4 5 7 8 9] [0 6]\n",
      "[1 2 3 4 5 6 8 9] [0 7]\n",
      "[1 2 3 4 5 6 7 9] [0 8]\n",
      "[1 2 3 4 5 6 7 8] [0 9]\n",
      "[0 3 4 5 6 7 8 9] [1 2]\n",
      "[0 2 4 5 6 7 8 9] [1 3]\n",
      "[0 2 3 5 6 7 8 9] [1 4]\n",
      "[0 2 3 4 6 7 8 9] [1 5]\n",
      "[0 2 3 4 5 7 8 9] [1 6]\n",
      "[0 2 3 4 5 6 8 9] [1 7]\n",
      "[0 2 3 4 5 6 7 9] [1 8]\n",
      "[0 2 3 4 5 6 7 8] [1 9]\n",
      "[0 1 4 5 6 7 8 9] [2 3]\n",
      "[0 1 3 5 6 7 8 9] [2 4]\n",
      "[0 1 3 4 6 7 8 9] [2 5]\n",
      "[0 1 3 4 5 7 8 9] [2 6]\n",
      "[0 1 3 4 5 6 8 9] [2 7]\n",
      "[0 1 3 4 5 6 7 9] [2 8]\n",
      "[0 1 3 4 5 6 7 8] [2 9]\n",
      "[0 1 2 5 6 7 8 9] [3 4]\n",
      "[0 1 2 4 6 7 8 9] [3 5]\n",
      "[0 1 2 4 5 7 8 9] [3 6]\n",
      "[0 1 2 4 5 6 8 9] [3 7]\n",
      "[0 1 2 4 5 6 7 9] [3 8]\n",
      "[0 1 2 4 5 6 7 8] [3 9]\n",
      "[0 1 2 3 6 7 8 9] [4 5]\n",
      "[0 1 2 3 5 7 8 9] [4 6]\n",
      "[0 1 2 3 5 6 8 9] [4 7]\n",
      "[0 1 2 3 5 6 7 9] [4 8]\n",
      "[0 1 2 3 5 6 7 8] [4 9]\n",
      "[0 1 2 3 4 7 8 9] [5 6]\n",
      "[0 1 2 3 4 6 8 9] [5 7]\n",
      "[0 1 2 3 4 6 7 9] [5 8]\n",
      "[0 1 2 3 4 6 7 8] [5 9]\n",
      "[0 1 2 3 4 5 8 9] [6 7]\n",
      "[0 1 2 3 4 5 7 9] [6 8]\n",
      "[0 1 2 3 4 5 7 8] [6 9]\n",
      "[0 1 2 3 4 5 6 9] [7 8]\n",
      "[0 1 2 3 4 5 6 8] [7 9]\n",
      "[0 1 2 3 4 5 6 7] [8 9]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import LeavePOut\n",
    "\n",
    "lpo = LeavePOut(p=2)\n",
    "for train, val in lpo.split(data):\n",
    "    print(train, val)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 셔플 분할\n",
    "- 독립전인 분할을 만들지만 검증 세트가 중첩될 수 있음\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 0 7 2 9 4 3 6] [8 1]\n",
      "[8 5 3 4 7 9 6 2] [0 1]\n",
      "[0 6 8 5 3 7 1 4] [9 2]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "ss = ShuffleSplit(n_splits=3, test_size=0.2, random_state=42)\n",
    "\n",
    "for train, val in ss.split(data):\n",
    "    print(train, val)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 금융에서 교차 검증의 문제\n",
    "- 금융 데이터는 이분산성(heteroskedasticity)이라고도 하는 계열 상관과 시간 가변 표준 편차 떄문에 독립적이거나 동일한 분포가 아님\n",
    "- sklearn.model_selection TimeSeriesSplit은 시계여 데이터의 선형 순서를 다루는 것을 목표로함"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 사이킷런을 이용한 시계열 교차 검증\n",
    "- 데이터의 시계열적 특성은 교차 검증이 미래 데이터를 사용해 과거 데이터를 예측하는 상황을 초래한다는 것을 의미함\n",
    "- 최적의 경우라 해도 비현실적이고 미래 데이터가 과거 시간을 반영할 만큼 최악의 경우 데아터 스누핑(data snooping)임\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4] [5]\n",
      "[0 1 2 3 4 5] [6]\n",
      "[0 1 2 3 4 5 6] [7]\n",
      "[0 1 2 3 4 5 6 7] [8]\n",
      "[0 1 2 3 4 5 6 7 8] [9]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "for train, val in tscv.split(data):\n",
    "    print(train, val)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 제거, 엠바고, 조합적 CV\n",
    "- 금융 데아터의 경우 여러 기간의 가격에서 수익률이 계산되기 때문에 레이블이 중복 데이터 포인트에서 파생되는 경우가 많음\n",
    "- 트레이딩 전략의 맥락에서 자산의 포지션을 갖는 것을 의미하는 모델의 예측 결과는 이러한 결정이 평가되는 나중에만 알 수 있음\n",
    "- 모든 데이터가 실제 시점에서 발생하도록 보장함으로써 이 리스크를 해결할 필교가 있음\n",
    "    - 즉, 데이터는 실제로 사용 가능한며 모델의 입력으로 사용되는 시점에 알려짐\n",
    "    - 예를들어 재무 공시는 특정 기간을 언급할 수 있지만 그 이후에서야 이용할 수 있음 (먼저 포함하면 X)\n",
    "\n",
    "- 교참 검증을 금융 데이터와 트레이닝 맥락에 맞추기 위한 기법\n",
    "* 제거(pruning) : 검증 세트에서 시점(point-in-time) 데이터 포인트를 예측한 후 평가가 이뤄지는 훈련 데이터 포인트를 제거해 선견 편향을 방지함\n",
    "* 엠바고(embargoing) : 테스트 기간을 따르는 훈련 표본을 추가로 제거\n",
    "* 조합적 교차 검증(combined CV) : 전방 진행 CV는 테스트할 수 있는 과거 경로를 심각하게 제한함."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 사이킷런을 이용한 파라미터 조정과 옐로우브릭\n",
    "- 모델 선택은 일반적으로 상이한 알고리즘이나 상이한 설정(Configuration)으로 모델의 표본 외 성과에 대한 교차 검증을 반복적으로 수행함\n",
    "- config 설정은 하이퍼파라미터의 변화나 상이한 변수의 포함 또는 제외를 포함함\n",
    "\n",
    "- 옐로우브릭(Yellowsticks) 라이브러리는 sklearn API를 확장해 모델 선택 프로레스를 용이하게 하는 진단적 시각화 도구를 생성함\n",
    "- 이러한 도구들은 특성 간의 관계를 조사하고, 분류 또는 회귀 오차를 분석하고, 클러스터링 알고리즘 성과를 모니터하고, 텍스트 데이터의 특성을 검사해 모델 선택을 돕는 데 사용될 수 있다.\n",
    "\n",
    "\n",
    "#### 검증 곡선: 하이퍼파라미터의 영향을 그래프로 표현\n",
    "#### 학습 곡선: 현퍙 분산 트레이드오프의 진단\n",
    "- 학습 곡선은 모델의 교차 검증 성과가 추가 데이터로부터 혜택을 보는지 여부와 예측 오차가 편향에 기인하는지, 분산에 기인하는지를 결정하는 데 도움이 된다.\n",
    "\n",
    "#### 그리드 서치와 파이프라인을 이용한 파라미터 조정\n",
    "- 하이퍼파라미터 조정이 ML 워크플로의 핵심 요소이므로 이 프로세스를 자동화하는 도구가 존재함\n",
    "- sklearn GridSearchCV (모든 조합의 파라미터를 병렬로 교차검증, 결과 포착, 전체 데이터 세트에 대한 교차 검증 중 가장 성과가 좋은 파라미터 설정을 이용해 모델을 자동으로 훈련함)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quant",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
